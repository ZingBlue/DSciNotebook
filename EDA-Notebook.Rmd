---
title: "Code Notebook"
author: "Eileena Mathews, Hayden Pozzi, Rachel Perry, and Richard Liu"
date: "`r Sys.Date()`"
output: html_document
---
```{r include=FALSE}

```

## Introduction

In recent years, artificial intelligence (AI) has undergone a profound shift in public perception. Once seen primarily as a source of uncertainty or even risk, AI is now becoming something people feel increasingly comfortable with—if not socially or professionally expected to use. From writing assistants and chatbots to algorithmic recommendations in education, finance, and entertainment, AI has become an embedded feature of everyday life. While AI is often discussed through the lens of technical innovation, less attention has been given to how ordinary people experience its integration into their daily routines, decision-making, and institutional contexts.

To ground our analysis in real-world evidence, we draw on the Public Attitudes to AI dataset produced by the Ada Lovelace Institute in the United Kingdom. This nationally representative survey of over 4,000 UK adults provides insight into public perceptions of AI across 17 application domains, ranging from facial recognition to healthcare triage and welfare eligibility. Unlike purely technical assessments, this dataset centers the public’s trust, perceived benefits, concerns, and expectations of governance—making it uniquely suitable for social inquiry into AI’s impact on socidety. The transparency of its methodology, including sampling, weighting, and question design, positions it as a robust foundation for understanding public sentiment at a pivotal moment in AI adoption.

Our interest is also informed by emerging research such as Marc Zao-Sanders’ work, “How People Are Really Using Generative AI Now,” featured in the Harvard Business Review. His findings challenge popular narratives by revealing that individuals use AI for personal and professional purposes at around equal rates. 

This raises some of the interesting questions our project seeks to explore: How aware are people of AI in their everyday environments? Do they trust institutions and individuals to use it responsibly? How do attitudes differ across demographic or experiential lines? By analyzing public attitudes through this dataset, we aim to contribute to a growing understanding of how societies negotiate the benefist and risks of AI.

Here's a brief summary of the data set:
```{r}
library(readr)
ai_survey1 <- read_csv("how-do-people-feel-about-ai-main/262400371_Public Attitudes to AI Raw Data NA (1).csv")
# Prep data
# Remove ppt identifying as 'other' and remove 16 year old 
#ai_survey1 <- ai_survey1 %>%
#  filter(is.na(RS_Sex) | RS_Sex != 3) %>%
#  filter(CS_Age != "16")
str(ai_survey1)
```

## PRELIMINARY EXPLORATION
One variable that interested our group was how comfortable (or uncomfortable) people felt about being evaluated by AI during the job application process. While general attitudes toward AI tend to focus on abstract benefits like efficiency or fairness, the hiring context makes the technology personal. 

To explore this, we focused on the BENB_JOB series, which asks respondents to select perceived benefits of AI in determining job eligibility. We aimed to understand how people negotiate the tension between potential advantages (such as reducing human bias) and potential discomfort (such as feeling misrepresented or dehumanized by automated systems).

```{r}
library(scales)

top8 <- overall_ben %>% slice_max(pct, n = 8) %>% pull(benefit)

# Overall
overall_ben %>%
  filter(benefit %in% top8) %>%
  ggplot(aes(reorder(benefit, pct), pct)) +
  geom_col() + coord_flip() +
  scale_y_continuous(labels = percent) +
  labs(x = NULL, y = "Weighted % selecting",
       title = "Perceived benefits of AI in hiring (overall)")

# Gender comparison for the same top 8
ben_by_gender %>%
  filter(benefit %in% top8) %>%
  ggplot(aes(rs_sex, pct, fill = rs_sex)) +
  geom_col(position = "dodge") +
  facet_wrap(~benefit, ncol = 2, scales = "free_y") +
  scale_y_continuous(labels = percent) +
  labs(x = NULL, y = "Weighted % selecting", fill = NULL,
       title = "Benefits of AI in hiring by gender") +
  theme(legend.position = "bottom")
```
The graph indicates that people recognize certain practical advantages to using AI in hiring, particularly when it comes to making recruiters’ jobs easier and reducing human bias. These benefits received the highest levels of agreement, suggesting that the public sees AI as potentially useful for improving process efficiency and fairness.

However, there is noticeably less confidence in AI when it comes to accuracy and data security. Fewer respondents believe that AI will make hiring decisions more accurate, and even fewer trust that their personal information would be safer under AI systems. This contrast suggests that while AI may be viewed as helpful administratively, it is not yet trusted to handle the deeper responsibilities of judgment or protection that hiring decisions require.
